# Copy to .env and fill in your values

LLM_PROVIDER=grok

GROK_API_KEY=your_grok_api_key_here
GROK_ENDPOINT=https://cmu-llm-api-resource.services.ai.azure.com/openai/v1/
GROK_MODEL=grok-3

AZURE_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_API_KEY=your_azure_api_key_here
AZURE_API_VERSION=2024-12-01-preview
AZURE_MODEL=o4-mini

GENERATION_TEMPERATURE=0.2
JUDGE_TEMPERATURE=0.0
JUDGE_MAX_TOKENS=300
DECOMPOSE_MAX_TOKENS=300
REWRITE_MAX_TOKENS=100

EMBED_MODEL_NAME=all-MiniLM-L6-v2
CHUNK_SIZE_TOKENS=500
CHUNK_OVERLAP_TOKENS=100
TOP_K=5
ENHANCED_TOP_N=8

REQUEST_TIMEOUT=30
API_PORT=8000
STREAMLIT_PORT=8501
LLM_MAX_RETRIES=4
LLM_BACKOFF_BASE_S=1.0
LLM_BACKOFF_MAX_S=15.0
LLM_MIN_CALL_INTERVAL_S=0.5

CHUNK_PREVIEW_LEN=200
SCORE_PASS_THRESHOLD=3.5
SCORE_WARN_THRESHOLD=2.5
