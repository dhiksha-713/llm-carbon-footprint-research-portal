# Copy to .env and fill in your values
GEMINI_API_KEY=your_gemini_api_key_here

# Models
GENERATION_MODEL=gemini-3-flash-preview
JUDGE_MODEL=gemini-3-flash-preview

# Generation
GENERATION_TEMPERATURE=0.2
JUDGE_TEMPERATURE=0.0
MAX_OUTPUT_TOKENS=2048
JUDGE_MAX_TOKENS=300
DECOMPOSE_MAX_TOKENS=300
REWRITE_MAX_TOKENS=100
DECOMPOSE_TEMPERATURE=0.0
REWRITE_TEMPERATURE=0.0

# Embeddings
EMBED_MODEL_NAME=all-MiniLM-L6-v2
EMBED_BATCH_SIZE=32

# Chunking
CHUNK_SIZE_TOKENS=500
CHUNK_OVERLAP_TOKENS=100

# Retrieval
TOP_K=5
ENHANCED_TOP_N=8
MAX_SUB_QUERIES=4

# Download
REQUEST_TIMEOUT=30
REQUEST_DELAY_S=2

# Serving
API_HOST=0.0.0.0
API_PORT=8000
STREAMLIT_PORT=8501

# Evaluation
CHUNK_PREVIEW_LEN=200
SCORE_PASS_THRESHOLD=3.5
SCORE_WARN_THRESHOLD=2.5
