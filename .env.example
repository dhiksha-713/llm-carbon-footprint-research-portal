# Copy to .env and fill in your values

LLM_PROVIDER=gemini

GEMINI_API_KEY=your_gemini_api_key_here
GEMINI_MODEL=gemini-2.0-flash-lite

AZURE_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_API_KEY=your_azure_api_key_here
AZURE_API_VERSION=2024-12-01-preview
AZURE_MODEL=o4-mini

GENERATION_TEMPERATURE=0.2
JUDGE_TEMPERATURE=0.0
MAX_OUTPUT_TOKENS=2048
JUDGE_MAX_TOKENS=300
DECOMPOSE_MAX_TOKENS=300
REWRITE_MAX_TOKENS=100

EMBED_MODEL_NAME=all-MiniLM-L6-v2
CHUNK_SIZE_TOKENS=500
CHUNK_OVERLAP_TOKENS=100
TOP_K=5
ENHANCED_TOP_N=8

REQUEST_TIMEOUT=30
API_PORT=8000
STREAMLIT_PORT=8501

CHUNK_PREVIEW_LEN=200
SCORE_PASS_THRESHOLD=3.5
SCORE_WARN_THRESHOLD=2.5
