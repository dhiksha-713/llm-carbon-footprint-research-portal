source_id,title,authors,year,source_type,venue,url_or_doi,raw_path,processed_path,tags,relevance_note
strubell2019,Energy and Policy Considerations for Deep Learning in NLP,"Strubell E.; Ganesh A.; McCallum A.",2019,peer-reviewed paper,ACL 2019,https://arxiv.org/abs/1906.02629,data/raw/strubell2019.pdf,data/processed/strubell2019.json,"training; energy; NLP; GPU-hours",Foundational paper on NLP training carbon costs; introduces GPU-hour energy estimation formula
luccioni2022,Estimating the Carbon Footprint of BLOOM,"Luccioni A.S.; Viguier S.; Ligozat A.L.",2022,peer-reviewed paper,arXiv,https://arxiv.org/abs/2211.02001,data/raw/luccioni2022.pdf,data/processed/luccioni2022.json,"lifecycle; BLOOM; embodied; operational",Lifecycle analysis of BLOOM-176B; covers embodied and operational emissions
patterson2021,Carbon Emissions and Large Neural Network Training,"Patterson D. et al.",2021,technical report,arXiv / Google,https://arxiv.org/abs/2104.10350,data/raw/patterson2021.pdf,data/processed/patterson2021.json,"training; hardware; efficiency; Google",Google analysis of training emissions across multiple large models; hardware efficiency focus
schwartz2020,Green AI,"Schwartz R.; Dodge J.; Smith N.A.; Etzioni O.",2020,peer-reviewed paper,Communications of the ACM,https://arxiv.org/abs/1907.10597,data/raw/schwartz2020.pdf,data/processed/schwartz2020.json,"Green AI; Red AI; efficiency; reporting",Coins Red AI vs Green AI; argues for efficiency reporting as standard practice
henderson2020,Towards the Systematic Reporting of the Energy and Carbon Footprints of ML,"Henderson P. et al.",2020,peer-reviewed paper,JMLR,https://arxiv.org/abs/2002.05651,data/raw/henderson2020.pdf,data/processed/henderson2020.json,"reporting; standards; measurement; methodology",Proposes systematic ML reporting framework; covers measurement methodology gaps
luccioni2023,Power Hungry Processing: Watts Driving the Cost of AI Deployment?,"Luccioni A.S.; Jernite Y.; Strubell E.",2023,peer-reviewed paper,ACM FAccT 2023,https://arxiv.org/abs/2311.16863,data/raw/luccioni2023.pdf,data/processed/luccioni2023.json,"inference; deployment; energy; cost",Focuses on inference-time energy; shows inference can dominate lifecycle costs at scale
bannour2021,Evaluating the carbon footprint of NLP methods: a survey and analysis of existing tools,"Bannour N. et al.",2021,peer-reviewed paper,EMNLP 2021 SustaiNLP,https://aclanthology.org/2021.sustainlp-1.2,data/raw/bannour2021.pdf,data/processed/bannour2021.json,"tools; CodeCarbon; mlco2; NLP",Comparative evaluation of carbon estimation tools for NLP; benchmarks CodeCarbon vs mlco2
dodge2022,Measuring the Carbon Intensity of AI in Cloud Instances,"Dodge J. et al.",2022,peer-reviewed paper,ACM FAccT 2022,https://arxiv.org/abs/2206.05229,data/raw/dodge2022.pdf,data/processed/dodge2022.json,"cloud; carbon intensity; shifting; real-time",Measures real-time carbon intensity of cloud AI workloads; introduces spatial/temporal shifting
lacoste2019,Quantifying the Carbon Emissions of Machine Learning,"Lacoste A. et al.",2019,tool/paper,NeurIPS 2019 Workshop,https://arxiv.org/abs/1910.09700,data/raw/lacoste2019.pdf,data/processed/lacoste2019.json,"calculator; mlco2; hardware; estimation",Introduces the mlco2.ai calculator; methodology for estimating training emissions from hardware specs
canziani2016,An Analysis of Deep Neural Network Models for Practical Applications,"Canziani A.; Paszke A.; Culurciello E.",2016,peer-reviewed paper,arXiv,https://arxiv.org/abs/1605.07678,data/raw/canziani2016.pdf,data/processed/canziani2016.json,"CNN; benchmarking; energy; hardware",Early energy benchmarking of CNN architectures; baseline for hardware energy analysis
wu2022,Sustainable AI: Environmental Implications Challenges and Opportunities,"Wu C.J. et al.",2022,technical report,MLSys 2022,https://arxiv.org/abs/2111.00364,data/raw/wu2022.pdf,data/processed/wu2022.json,"Meta; production; training; inference",Meta system-level sustainability analysis; covers training and inference at production scale
anthony2020,Carbontracker: Tracking and Predicting the Carbon Footprint of Training Deep Learning Models,"Anthony L.F.W. et al.",2020,tool/paper,ICML 2020 Workshop,https://arxiv.org/abs/2007.03051,data/raw/anthony2020.pdf,data/processed/anthony2020.json,"tool; tracking; prediction; real-time",Introduces Carbontracker tool; real-time carbon tracking during training with prediction capability
ligozat2022,Unraveling the hidden environmental impacts of AI: A systematic review,"Ligozat A.L. et al.",2022,peer-reviewed paper,ACM Computing Surveys,https://arxiv.org/abs/2111.08323,data/raw/ligozat2022.pdf,data/processed/ligozat2022.json,"survey; methodology; embodied; gaps",Comprehensive survey of carbon estimation methodologies; identifies gaps in embodied carbon accounting
desislavov2023,Trends in AI Inference Energy Consumption: Beyond the Performance-vs-Parameter Laws of Deep Learning,"Desislavov R. et al.",2023,peer-reviewed paper,Sustainable Computing,https://arxiv.org/abs/2301.00774,data/raw/desislavov2023.pdf,data/processed/desislavov2023.json,"inference; energy; trends; efficiency",Analyzes trends in AI inference energy consumption; questions performance-vs-parameter scaling laws
faiz2024,LLMCarbon: Modeling the End-to-End Carbon Footprint of Large Language Models,"Faiz A. et al.",2024,peer-reviewed paper,ICLR 2024,https://arxiv.org/abs/2309.14393,data/raw/faiz2024.pdf,data/processed/faiz2024.json,"LLM; carbon; end-to-end; modeling",End-to-end carbon modeling framework for LLMs covering training and inference lifecycle
lannelongue2021,Green Algorithms: Quantifying the Carbon Footprint of Computation,"Lannelongue L. et al.",2021,peer-reviewed paper,Advanced Science,https://arxiv.org/abs/2007.07610,data/raw/lannelongue2021.pdf,data/processed/lannelongue2021.json,"algorithms; computation; carbon; calculator",Framework for estimating carbon footprint of any computational task; Green Algorithms calculator
samsi2023,From Words to Watts: Benchmarking the Energy Costs of Large Language Model Inference,"Samsi S. et al.",2023,peer-reviewed paper,IEEE HPEC 2023,https://arxiv.org/abs/2310.03003,data/raw/samsi2023.pdf,data/processed/samsi2023.json,"LLM; inference; energy; benchmarking",Benchmarks energy costs of LLM inference across model sizes and hardware configurations
garcia_martin2019,Estimation of Energy Consumption in Machine Learning,"Garcia-Martin E. et al.",2019,peer-reviewed paper,JMLR,https://arxiv.org/abs/1906.02893,data/raw/garcia_martin2019.pdf,data/processed/garcia_martin2019.json,"energy; estimation; ML; survey",Survey of energy estimation methods for ML; covers software and hardware approaches
verdecchia2023,A Systematic Review of Green AI,"Verdecchia R. et al.",2023,peer-reviewed paper,WIREs Data Mining and Knowledge Discovery,https://arxiv.org/abs/2301.11047,data/raw/verdecchia2023.pdf,data/processed/verdecchia2023.json,"Green AI; systematic review; efficiency",Systematic review of 98 Green AI papers; taxonomy of energy efficiency approaches
thompson2020,The Computational Limits of Deep Learning,"Thompson N.C. et al.",2020,peer-reviewed paper,IEEE Proceedings,https://arxiv.org/abs/2007.05558,data/raw/thompson2020.pdf,data/processed/thompson2020.json,"computation; limits; scaling; growth",Analyzes exponential growth of compute in deep learning and sustainability implications
